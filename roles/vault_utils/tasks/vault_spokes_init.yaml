---
- name: Find managed clusters
  kubernetes.core.k8s_info:
    kind: ManagedCluster
    api_version: "cluster.open-cluster-management.io/v1"
  register: managed_clusters

- name: Set resource fact
  ansible.builtin.set_fact:
    resources: "{{ managed_clusters['resources'] }}"

- name: Do nothing when no managed clusters are found
  ansible.builtin.meta: end_play
  when: resources | length == 0 or managed_clusters.failed or not managed_clusters.api_found

# These three loops are not done in one pass because sometimes the managedCluster is not fully
# populated with all the attributes from the start
- name: Loop over returned ACM managedclusters caBundle and name
  ansible.builtin.set_fact:
    clusters: "{{ clusters | default({}) | combine({item.metadata.name:
      {'caBundle': item.spec.managedClusterClientConfigs[0].caBundle | b64decode,
       'name': item.metadata.name}}) }}"
  loop: "{{ resources }}"
  when: item.spec.managedClusterClientConfigs[0].caBundle is defined
  loop_control:
    label: "{{ item.metadata.name }}"

- name: Extract ClusterGroup
  ansible.builtin.set_fact:
    clusters: "{{ clusters | default({}) | combine({item.metadata.name: {'clusterGroup': item.metadata.labels.clusterGroup}}, recursive=True) }}"
  when: "'clusterGroup' in item.metadata.labels"
  loop: "{{ resources }}"
  loop_control:
    label: "{{ item.metadata.name }}"

- name: Loop over returned ACM managedclusters url
  ansible.builtin.set_fact:
    clusters: "{{ clusters | default({}) | combine({item.metadata.name:
    {'server_api': item.spec.managedClusterClientConfigs[0].url,
     'cluster_fqdn': item.spec.managedClusterClientConfigs[0].url | ansible.builtin.urlsplit('hostname') | regex_replace('^api\\.', '')}}, recursive=True) }}"
  loop: "{{ resources }}"
  when: item.spec.managedClusterClientConfigs[0].url is defined
  loop_control:
    label: "{{ item.metadata.name }}"

# vault_path is 'hub' when 'local-cluster' and fqdn otherwise
- name: Loop over clusters to set the vault_path
  ansible.builtin.set_fact:
    clusters: "{{ clusters | default({}) |
      combine({item.key: {'vault_path': (item.value.name == 'local-cluster') | ternary('hub', item.value.cluster_fqdn)}}, recursive=True) }}"
  loop: "{{ clusters | dict2items }}"
  loop_control:
    label: "{{ item.key }}"

# These three steps will only work on ACM 2.12 which uses these secrets to connect to the spokes
- name: Fetch all ACM secrets
  kubernetes.core.k8s_info:
    kind: Secret
    label_selectors:
    - "apps.open-cluster-management.io/secret-type=acm-cluster"
  register: acm_secrets_raw

- name: Set acm secrets fact
  ansible.builtin.set_fact:
    acm_secrets: "{{ acm_secrets_raw.resources }}"

- name: Set cleaned_acm_secrets fact
  ansible.builtin.set_fact:
    cleaned_acm_secrets: "{{ acm_secrets | rhvp.cluster_utils.parse_acm_secrets }}"
  when: acm_secrets | length > 0

- name: Merge the two dicts together
  ansible.builtin.set_fact:
    clusters_info: "{{ clusters | default({}) | combine(cleaned_acm_secrets, recursive=True) }}"
  when: acm_secrets | length > 0

# These steps will only work on ACM >= 2.13 which uses managed service accounts to connect to remote spokes
# ACM creates a namespace named like the remote cluster and we loop those
- name: Get the ACM secrets when on ACM >=2.13
  kubernetes.core.k8s_info:
    kind: Secret
    namespace: "{{ item.metadata.name }}"
    name: application-manager
  register: msa_secrets
  loop: "{{ resources }}"
  when: acm_secrets | length == 0
  loop_control:
    label: "{{ item.metadata.name }}"

# We use item.item.metadata.name because the item used in the loop to fetch the
# secret is a managedcluster type
- name: Loop over returned ACM managedclusters url
  ansible.builtin.set_fact:
    clusters: "{{ clusters | default({}) | combine({item.item.metadata.name: {'bearerToken': item.resources[0].data.token | b64decode}}, recursive=True) }}"
  loop: "{{ msa_secrets.results }}"
  when:
    - acm_secrets | length == 0
    - msa_secrets.results | length > 0
  loop_control:
    label: "{{ item.item.metadata.name }}"

- name: Set cluster_info fact
  ansible.builtin.set_fact:
    clusters_info: "{{ clusters }}"
  when: acm_secrets | length == 0

- name: Write out CAs
  ansible.builtin.copy:
    content: "{{ item.value['caBundle'] }}"
    dest: "/tmp/{{ item.key }}.ca"
    mode: "0640"
  loop: "{{ clusters_info | dict2items }}"
  when: item.value['caBundle'] is defined
  loop_control:
    label: "{{ item.key }}"

# FIXME(bandini): validate_certs is false due to an ACM bug when using
# letsencrypt certificates with API endpoints: https://issues.redhat.com/browse/ACM-4398
# We always verify the CA chain except when letsencrypt.api_endpoint is set to true
- name: If we are using letsencrypt on the API endpoints we cannot use the validate_certs later
  ansible.builtin.set_fact:
    validate_certs_api_endpoint: "{{ not letsencrypt.api_endpoint | default(True) | bool }}"

- name: Fetch remote external secrets from remote cluster
  kubernetes.core.k8s_info:
    api_key: "{{ item.value['bearerToken'] }}"
    ca_cert: /tmp/{{ item.key }}.ca
    host: "{{ item.value['server_api'] }}"
    kind: Secret
    namespace: "{{ external_secrets_ns }}"
    name: "{{ external_secrets_secret }}"
    api_version: v1
    validate_certs: "{{ validate_certs_api_endpoint }}"
  register: remote_external_secrets_sa
  # We are allowed to ignore errors here because a spoke might be down or unreachable
  # if a spoke is not reachable then its ['token'] field will not be set which
  # will leave the ['esoToken'] field empty in the dict which will make it so that
  # the spoke gets skipped
  ignore_errors: true
  # We add no_log: '{{ hide_sensitive_output | default(true) }}' here because in case of a remote failure secret bits might
  # end up in the log. Unfortunately ansible is currently not easily able to control
  # output in a loop (see
  # https://serverfault.com/questions/1059530/how-to-not-print-items-in-an-ansible-loop-error-without-no-log)
  no_log: '{{ hide_sensitive_output | default(true) }}'
  when:
    - clusters_info[item.key]['bearerToken'] is defined
    - clusters_info[item.key]['server_api'] is defined
    - clusters_info[item.key]['caBundle'] is defined
  loop: "{{ clusters_info | dict2items }}"
  loop_control:
    label: "{{ item.key }}"

- name: Fetch remote legacy external secrets from remote cluster
  kubernetes.core.k8s_info:
    api_key: "{{ item.value['bearerToken'] }}"
    ca_cert: /tmp/{{ item.key }}.ca
    host: "{{ item.value['server_api'] }}"
    kind: Secret
    namespace: "{{ legacy_external_secrets_ns }}"
    name: "{{ legacy_external_secrets_secret }}"
    api_version: v1
    validate_certs: "{{ validate_certs_api_endpoint }}"
  register: remote_legacy_external_secrets_sa
  # We are allowed to ignore errors here because a spoke might be down or unreachable
  # if a spoke is not reachable then its ['token'] field will not be set which
  # will leave the ['esoToken'] field empty in the dict which will make it so that
  # the spoke gets skipped
  ignore_errors: true
  # We add no_log: '{{ hide_sensitive_output | default(true) }}' here because in case of a remote failure secret bits might
  # end up in the log. Unfortunately ansible is currently not easily able to control
  # output in a loop (see
  # https://serverfault.com/questions/1059530/how-to-not-print-items-in-an-ansible-loop-error-without-no-log)
  no_log: '{{ hide_sensitive_output | default(true) }}'
  when:
    - clusters_info[item.key]['bearerToken'] is defined
    - clusters_info[item.key]['server_api'] is defined
    - clusters_info[item.key]['caBundle'] is defined
  loop: "{{ clusters_info | dict2items }}"
  loop_control:
    label: "{{ item.key }}"

# 'token' will be empty if the remote cluster has no external-secrets
# app configured and running
- name: Loop over returned external secrets tokens
  ansible.builtin.set_fact:
    clusters_info: "{{ clusters_info | default({}) | combine({item['item']['key']: {'esoToken': item['resources'][0]['data']['token'] | b64decode, 'activeExternalSecretsNs': external_secrets_ns, 'activeExternalSecretsSa': external_secrets_sa}}, recursive=True) }}"
  loop: "{{ remote_external_secrets_sa.results }}"
  when: item['resources'][0]['data']['token'] is defined
  loop_control:
    label: "{{ item['item']['key'] }}"

# 'token' will be empty if the remote cluster has no legacy golang-external-secret
# app configured and running - only check legacy if regular external secrets were not found
- name: Loop over returned legacy external secrets tokens
  ansible.builtin.set_fact:
    clusters_info: "{{ clusters_info | default({}) | combine({item['item']['key']: {'esoToken': item['resources'][0]['data']['token'] | b64decode, 'activeExternalSecretsNs': legacy_external_secrets_ns, 'activeExternalSecretsSa': legacy_external_secrets_sa}}, recursive=True) }}"
  loop: "{{ remote_legacy_external_secrets_sa.results }}"
  when:
    - item['resources'][0]['data']['token'] is defined
    - clusters_info[item['item']['key']]['esoToken'] is not defined
  loop_control:
    label: "{{ item['item']['key'] }}"

# At this point clusters_info contains a per cluster hash table with *all* the right attributes. For example:
# "mcg-one": {
#   "bearerToken": "ey...",
#   "caBundle": "-----BEGIN CERTIFICATE-----\nMIIDMjCCA",
#   "clusterGroup": "group-one",
#   "cluster_fqdn": "mcg-one.blueprints.rhecoeng.com",
#   "vault_path": "hub" (when the hub) and the cluster_fqdn when not hub,
#   "esoToken": (optional) only if there was an external golang-external-secrets namespace+service account
#   "name": "mcg-one",
#   "server_api": "https://api.mcg-one.blueprints.rhecoeng.com:6443",
# }
- name: Dump CABundles into the vault
  kubernetes.core.k8s_exec:
    namespace: "{{ vault_ns }}"
    pod: "{{ vault_pod }}"
    command: bash -e -c "echo '{{ item.value['caBundle'] }}' > /tmp/{{ item.value['vault_path'] }}.ca"
  loop: "{{ clusters_info | dict2items }}"
  when:
    - item.value['esoToken'] is defined
    - item.key != "local-cluster"
  loop_control:
    label: "{{ item.key }}"

- name: Is kubernetes backend already enabled
  no_log: '{{ hide_sensitive_output | default(true) }}'
  kubernetes.core.k8s_exec:
    namespace: "{{ vault_ns }}"
    pod: "{{ vault_pod }}"
    command: bash -e -c "if vault auth list | grep -e ^'{{ item.value['vault_path'] }}'; then
        echo done; else
        vault auth enable -path='{{ item.value['vault_path'] }}' kubernetes; fi"
  loop: "{{ clusters_info | dict2items }}"
  when:
    - item.value['esoToken'] is defined
    - item.key != "local-cluster"
  loop_control:
    label: "{{ item.key }}"

- name: Configure kubernetes backend
  no_log: '{{ hide_sensitive_output | default(true) }}'
  kubernetes.core.k8s_exec:
    namespace: "{{ vault_ns }}"
    pod: "{{ vault_pod }}"
    command: bash -e -c "vault write auth/{{ item.value['vault_path'] }}/config
        token_reviewer_jwt=\"{{ item.value['esoToken'] }}\"
        kubernetes_host=\"{{ item.value['server_api'] }}\"
        kubernetes_ca_cert=@/tmp/{{ item.value['vault_path'] }}.ca"
  loop: "{{ clusters_info | dict2items }}"
  when:
    - item.value['esoToken'] is defined
    - item.key != "local-cluster"
  loop_control:
    label: "{{ item.key }}"

- name: Configure spoke policy template
  kubernetes.core.k8s_exec:
    namespace: "{{ vault_ns }}"
    pod: "{{ vault_pod }}"
    command: >
      bash -e -c "echo \"path \\\"secret/data/{{ item.value['vault_path'] }}/*\\\" {
        capabilities = {{ vault_spoke_capabilities }} }\" > /tmp/policy-{{ item.value['vault_path'] }}.hcl"
  loop: "{{ clusters_info | dict2items }}"
  when:
    - item.value['esoToken'] is defined
    - item.key != "local-cluster"
  loop_control:
    label: "{{ item.key }}"

- name: Configure spoke pushsecrets policy template
  kubernetes.core.k8s_exec:
    namespace: "{{ vault_ns }}"
    pod: "{{ vault_pod }}"
    command: >
      bash -e -c "echo \"path \\\"secret/data/{{ vault_pushsecrets_policy }}/*\\\" {
        capabilities = {{ vault_pushsecrets_capabilities }} }\" >> /tmp/policy-{{ item.value['vault_path'] }}.hcl"
  loop: "{{ clusters_info | dict2items }}"
  when:
    - item.value['esoToken'] is defined
    - item.key != "local-cluster"
  loop_control:
    label: "{{ item.key }}"

- name: Configure spoke pushsecrets metadata policy template
  kubernetes.core.k8s_exec:
    namespace: "{{ vault_ns }}"
    pod: "{{ vault_pod }}"
    command: >
      bash -e -c "echo \"path \\\"secret/metadata/{{ vault_pushsecrets_policy }}/*\\\" {
        capabilities = {{ vault_pushsecrets_capabilities }} }\" >> /tmp/policy-{{ item.value['vault_path'] }}.hcl"
  loop: "{{ clusters_info | dict2items }}"
  when:
    - item.value['esoToken'] is defined
    - item.key != "local-cluster"
  loop_control:
    label: "{{ item.key }}"

- name: Configure policy for spokes
  kubernetes.core.k8s_exec:
    namespace: "{{ vault_ns }}"
    pod: "{{ vault_pod }}"
    command: "vault policy write {{ item.value['vault_path'] }}-secret /tmp/policy-{{ item.value['vault_path'] }}.hcl"
  loop: "{{ clusters_info | dict2items }}"
  when:
    - item.value['esoToken'] is defined
    - item.key != "local-cluster"
  loop_control:
    label: "{{ item.key }}"

- name: Configure kubernetes role for spokes
  kubernetes.core.k8s_exec:
    namespace: "{{ vault_ns }}"
    pod: "{{ vault_pod }}"
    command: >
      vault write auth/"{{ item.value['vault_path'] }}"/role/"{{ item.value['vault_path'] }}"-role
        bound_service_account_names="{{ item.value['activeExternalSecretsSa'] }}"
        bound_service_account_namespaces="{{ item.value['activeExternalSecretsNs'] }}"
        policies="default,{{ vault_global_policy }}-secret,{{ vault_pushsecrets_policy }}-secret,{{ item.value['vault_path'] }}-secret" ttl="{{ vault_spoke_ttl }}"
  loop: "{{ clusters_info | dict2items }}"
  when:
    - item.value['esoToken'] is defined
    - item.key != "local-cluster"
  loop_control:
    label: "{{ item.key }}"
